# EC463/464 - Team 2
## Autonomous Legged Robot
This repository is for the senior design class team 2. PuppyPi, our autonomous-legged robot is an AI guide dog, providing visually-impaired users with timely information about obstacle positions for safer navigation. The robot's first function is to reach a pre-determined destination using an audio-based user interface. It will have the ability to understand the building's map based on lines on the floor and gather information about the building by scanning QR codes placed on the floor. Decoding each QR code provides information about the location, helping the robot dog decide where to go and guiding the user to the intended destination.

#

**Documentation**

* [Hardware documentation](https://github.com/PicassoEEA/legged_robot/tree/main/Hardware_Info)
* This hardware documentation will give a brief introduction of all hardware we have used in this project including Oak-d camera, Lidar, RGB camera, embedded battery, raspberry pi and so on. All dimensions like the angle and fps of camera, weight of Oak-d, scope of lidar should be found in this documentation. 

* [Sofware documentation](https://github.com/PicassoEEA/legged_robot/tree/main/Software_Info)
* This software documentation mainly describe the connection between raspberry pi and another control end(PC or app control). The tutorial of using VNC viewer and hotspot wifi to make that connection should be found here.

#

**Demo Video**

Here are some demo videos of the performance of the robot dog(https://drive.google.com/drive/folders/1-3u4MFsINuggVaRiVoGgDMhkyEvuZgEe?usp=sharing)

#


## Team member
Bowen Ma, Shun Zhang, Xiteng Yao, Yichen Wang, Yihe Bi
